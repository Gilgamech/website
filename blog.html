<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/> 
		<link rel="shortcut icon" href="https://www.gilgamech.com/images/favicon.ico" type="image/x-icon"/>
		<meta name="viewport" content="width=device-width","initial-scale=1">
<meta property="og:title" content="Gilgamech's blogging mathematically again." />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.Gilgamech.com/blog.html" />
<meta property="og:description" content="Creating art from math and philosophy from technology. Have a look at the world from a unique point of view." />
<meta property="og:image" content="https://www.gilgamech.com/images/BigG.jpg" />
<meta name="description" content="Creating art from math and philosophy from technology. Have a look at the world from a unique point of view.">
<meta name="keywords" content="blog">
<meta name="author" content="Stephen Gillie">
		<title>Gilgamech Technologies</title>
		<script src="https://www.Sparational.com/Sparational.js"></script>
		<script src="https://www.Gilgamech.com/js/sitelets.js"></script>
		<script src="https://www.Gilgamech.com/js/cryptography.js"></script>
		<link href="https://www.Gilgamech.com/css/normalize.css" rel="stylesheet" type="text/css">
		<link href="https://www.Gilgamech.com/css/Gilgamech.css" rel="stylesheet" type="text/css">
	</head>
	<body>
		<div id="titleParent" class="titleContainer">
			<a class="pageTitle " href="/">Gilgamech Technologies</a>
		</div>
		<div id="headWrapper">
<script type="application/javascript"> 
const colors = [	"#E50000", //red	"#FF8D00",//orange 	"#FFFF00", //yellow	"#028121",//green 	"#004CFF",//indigo 	"#760088",//purple 	"#FFFFFF",//white	"#FFAFC7",//pink	"#73D7EE",//teal	"#000000"//black
];

window.addEventListener("mousedown", (e) => {
	const color = colors.shift();
	var foreground = "#000000"
if (parseInt(color.substr(1,2), 16)+parseInt(color.substr(3,2), 16)+parseInt(color.substr(5,2), 16) < 500){
	foreground = "#FFFFFF"
}

 document.documentElement.style.setProperty("--highlight-color", color);
 document.documentElement.style.setProperty("--foreground-color", foreground);
 colors.push(color);
});

var feb4Blog = [
	["What is a neural network?","h2"],
	["Here is a neuron from a miniature 'neural network in a spreadsheet' upgraded to a JS-driven table. It came from a Medium article by MoralRobots that has since been deleted by its author.","p"],
	["Here you can control both inputs, the synapse weight, and the threshold.","p"],
	["","div","0204TableHolder"],
	["The article offered 2 simple modes of operation: ","p"],
	["","ul","list0204"],
	["Setting the weight to 1 makes this circuit into an OR circuit, where setting either input to 1 will set the output to 1. Only when both are set to 0 will the output be 0, so it's not an XOR. And setting the weight to 0.6 turns this into an AND circuit, where both inputs must be 1 to turn the output to 1.","p"],
	["When you start playing with it, you may start using decimal numbers to get more fine-tuned results. This sorta works in simulation, but not with individual bits - these must be 0s or 1s. But there is a quantum solution for this as well. Readers of my Gillogisms know where this is going.","p"]
]

var feb4List = [
	["Synapse weight set to 1 - OR circuit","li"],
	["Synapse weight set to 0.6 - AND circuit","li"]
];

var feb5Blog = [
	["What is a neural network?","h2"],
	["Right now, neural networks are arrays stored and computed on massive GPUs in cloud servers.","p"],
	["How much would one server cost?","h2"],
	["Some numbers from Tom Goldstein (now-deleted), Mayank Mishra, and a little value-add. Tom estimates that 'A100 GPU costs about $3/hr to rent on Azure.","p"],
	["","div","0205Table2Holder"],
	["To verify, we can find the specific model of server that comes with 8x A100 GPUs: 'Standard_ND96amsr_A100_v4'. This model isn't available in all regions, but it *is* available in the East US region. With a 3 year reservation, the Azure Pricing Calculator says this class of server costs $13,749.40 per month, which is close. This is just for the server, and not for bandwidth.","p"],
	["How many queries can one server answer?","h2"],
	["","div","0205Table1Holder"],
	["When compared in terms of parameters per millisecond per A100, these estimations become somewhat consistent. Each GPU can process about 400-500 million parameters per millisecond, and this rate lets the 175-176 billion parameter models produce about 20 words per second. At 86400 seconds/day, 20 words/sec gives 1.73 million words/day. At 30 words/query, this gives 57,670 queries/day per server. ","p"],
	["How much would one day cost?","h2"],
	["Tom estimates (and I agree) that 1 million users could easily average 10 queries per day, so 10 million queries/day isn't unreasonable. To support 10 million queries/day, 174 instances are needed. Tom estimates this costs $100k/day or $3 million/month.","p"],
	["","div","0205Table3Holder"],
	["So again, this is a fairly accurate estimate.","p"]
]

var feb5Table1 = [
	["Model", "#A100s", "HW/mo", "OS/mo", "Total/mo", "Total/day", "Total/hour", "Total/hour/A100"],
	["Standard_ND96amsr_A100_v4",8, 10525.72, 3223.68],
	["1/8 server (represents 1x A100)",1, 1315.715, 402.96]
]

var feb5Table2 = [
	["Model", "Parameters", "ms", "sec/ms", "#A100s","Param/ms","Param/ms/#A100s","words/sec","words/day","queries/day"],
	["3 billion", "3 billion", 6, 1000, 1],
	["ChatGPT 1GPU", "175 billion", 350, 1000, 1],
	["ChatGPT", "175 billion", 50, 1000, 8],
	["BLOOM 176B", "176 billion", 45, 1000, 8]
]

var feb5Table3 = [
	["ND96amsr", "1 server", "174 servers"],
	["Month","13.75k"],
	["Year","165k"],
]

var feb6Blog = [
	["What is a neural network?","h2"],
	["Several neurons connected output to inputs. Building off Part 1, what is a neuron? Weighted inputs (synapses) that sum to an activation value, which modify an output if the activation value is greater than an threshold value.","p"],
	["In a neural network, neurons are stratified into layers:","p"],
	["","ul","list0206"],
	["Here is the Part 1 neuron condensed into a row, and copied. The mid layer synapses are fed from the input layer, and the output layer's synapses are fed from the mid layer. This network is too small to really be useful, but it gives a functional concept of what larger models are doing.","p"],
	["Inputs","span"],
	["1","input","0206inputA","propagateValues0206();"],
	["0","input","0206inputB","propagateValues0206();"],
	["","div","0206TableHolder"],
	["There's one more part omitted from Part 1 - the memory and weight update. These are a function that look at the output, and the history, and determine how to modify the weights of each synapse. If increasing the weight increases progress towards the desired goal (aka good) the weight will continue getting increased. But if not, the weight will become decreased.","p"]
]


var feb6List = [
	["In the input layer, each input neuron needs one synapse per input. More input neurons will give more input granularity.","li"],
	["In the middle and output layers, each neuron needs one synapse foreach neuron of the layer above.","li"],
	["More middle neurons, and more layers will again give more granularity.","li"],
	["In the output layer, one neuron is needed foreach output value.","li"]
]

var feb9Blog = [
	["What is a neural network?","h2"],
	["The near future of neural networks involves a new type of compute hardware. Instead of CPUs with massive very-general-purpose compute units, or GPUs with massive pipelines of compute units, AI will need TPUs and beyond (as AIPU was already taken), which have specialized Multiply-Accumulate compute areas. These are a much more complex mix of very small and specialized compute and memory units, tied together in a physical network that begins to resemble brain neurons in construction. These have greatly reduced power consumption requirements for matrix multiplication.","p"],
	["A very apparent technology goal is to reduce the power and processing requirements down to where the processors and power supply for a model like ChatGPT could fit within a Boston Dynamics robot. This would put our society at about the point of Issac Newton's I, Robot, where general-purpose robots become a common appliance.","p"],
	["How do these stack up against the A100?","h2"],
	["","div","0209Table2Holder"],
	["(Note here that the TPUv1 has a -correction- TDP of 230, but the article lists it as 23.)","p"],
	["In his (now-deleted) Twitter thread, Tom Goldstein remarked that ChatGPT wouldn't fit on a single A100, but instead you'd need at least 5, implying the model is between 320-400 GB. This means the model's power requirements are a minimum of 2 kW just for A100s, and probably closer to 3.5 kW for the full ND96amsr mentioned in Sunday's blog post. Across one hour, this is 3.5 kWh, or about 1-2 days of electricity use for the average American. For 174 servers, this is close to 1 American's annual electrical use per hour. For this to work on a Boston Dynamics robot, the brains would have to be in a rackmount tower.","p"],
	["Ergo's tremendous TOPS/Watts makes it a great next step. (Note here again that the Ergo has a TOPS/W of 200 based on the numbers provided by the article, but the article lists it as merely 54.) It's 64 (or 17) times more efficient than the A100, meaning that if they were able to scale it up 100 times - from 4 GB to 400 GB, it could operate ChatGPT for about 54.6 (or 202) Watts - for one hour would be 54.6 (or 202) Watt-hours, which is equal to 1 (or 4) high-end laptop batter(y/ies). This package would be trivial to stuff inside a Boston Dynamics robot, and the real difficulty then would be instrumenting the robot and feeding the sensor inputs into the chip.","p"],
	["Beyond Ergo","h2"],
	["This is the first of many new potentially post-MAC chip designs, and the first of many new AI models. And probably just scratching the surface of efficiency for this mathematical model.","p"]
]

var feb9Table = [
	["Processor","Date Introduced","Process node (nm)","Die size (mm²)","On-chip Memory","Clock Speed (MHz)","Smallest Memory Configuration (GB)","TDP (Watts)","TOPS","TOPS/W"],
	["TPUv1",2016,28,"331",28,700,"8 DDR3",230,75],
	["TPUv2",2017,16,"<625",32,700,"16 HBM",280,45],
	["TPUv3",2018,16,"<700",32,940,"32 HBM",450,90],
	["TPUv4",2021,7,"<400",144,1050,"32 HBM",175,"?"],
	["Edgev1",2018,"","","","","",2,4],
	["Ergo",2020,"",49,"","","",0.020,4],
	["*A100*",2020,7,826,80,1215 ,"80 HBM2 ",400,1248]
]

var feb11Blog = [
	["What is a neural network?","h2"],
	["A neural network is a finite state machine that modifies itself to have optimal states for any input. Our brains are fascinating networks of neurons - all animal brains are. Neural networks have been a driving force of change on Earth several million years, driving everything from jellyfish to Tyrannosarus Rex. And now they'll power our internet search too.","p"],
	["If you need a problem solved, throw a neural network at it. This has been the answer for millennia. The big difference now is like the electric motor and/or internal combustion engine - you don't need to feed the horse (or office worker) that it's attached to anymore. And just like there were millions of horses at one point, and they now number in the tens of thousands - so too the number of humans on Earth will dwindle to probably 3-4 billion. Making highly energy efficient AI will be one of the greatest things humans have done for the environment.","p"],
	["How do these stack up against the A100?","h2"],
	["The human neuroprocessor is a fascinatingly complex computational instrument. Approximately 100 billion physical neurons are powered by about 20 Watts, giving an estimated 1000 TOPS, for an amazing 51.55 TOPS/W. ","p"],
	["","div","0211Table1Holder"],
	["19.4 Watts was determined from the brain using about 20% of a human body's calories, which is approximately 2000 calories per day. Divided across 24 hours, this is 83.3 calories/hour, of which 20% is 16.67 calories - or 0.0194 kWh. 1 kTOPS was derived from the extremely conservatively estimated 10^15 calculations per second from Drexler 2018. The actual figure may be 10-10k times higher, depending on source.","p"],
	["It's notable our computers are beginning to get into the neighborhood of our own brains, in terms of software models and hardware resources. We may currently have both devices as powerful as our own brains, and also as efficient as our own brains. But no device yet is both as powerful and efficient, yet. This means there's still time to find (or be) the market player who makes that crucial innovation, and invest before most of the market does.","p"],
	["From David Ireland on Stack Exchange:'","p"],
	[">Parameters is a synonym for weights, which is the term most people use for a neural networks parameters (and indeed in my experience it is a term that machine learners will use in general whereas parameters is more often found in statistics literature). Batch size, learning rate etc. are hyper-parameters which basically means they are user specified, whereas weights are what the learning algorithm will learn through training.'","p"],
	[">It won’t have 175million nodes, if you think of a simpler neural network then the number of parameters is how many connections there are between nodes. If there was a NN with 1 layer of 2 neurons followed by a layer with 3 neurons, then an output layer with 1 neuron there would be 9 parameters (you could draw this out to see what I mean).","p"],
	["Inputs","span"],
	["1","input","0211input_A","propagateValues0210();"],
	["0","input","0211input_B","propagateValues0210();"],
	["","div","0211Table2Holder"],
	["The model described above, with no weights on the input layer, 2 weights each for the 3 mid layer neurons, and 3 weights on the output neuron. This gives the 9 neurons that David was describing. Based on this, it sounds as though weights may also be considered synonymous with synapses.","p"],
	["Comparison of software models","h2"],
	["Earth brains are a software-driven hardware model, creating and breaking synapses as the model demands. Its extreme efficiency enables vast processing capability.","p"],
	["","div","0211Table3Holder"],
	["The human brain is a tremendous software model, utilizing something approaching 5700 times as many parameters as ChatGPT's rumoured current implementation. In this way, FPGAs may lead the way in being the easiest to customize to a given neural network - especially if they specialized in accumulated multiplication, the neural network secret sauce. FPGAs become a kind of general-compute processor for AI models. To put another way, an AI model will run fastest (or most efficient) on an ASIC designed specifically for it, an FPGA will be second-fastest or second-most efficient, and a GPU like the A100 will be the third-fastest or third-most-efficient. At least once these market segments gain maturity - the AI ASIC market is just getting started, and the FPGA market has been largely ignored for years. (Decades?) This is likely what the Ergo, Ryzen, and other chips are likely doing - FPGA-accelerated MAC.","p"]
]

var feb11Table1 = [
	["Processor","Date Introduced","TDP (Watts)","TOPS","TOPS/W"],
	["TPUv3",2018,450,90],
	["Edgev1",2018,2,4],
	["Ergo",2020,0.020,4],
	["*A100*",2020,400,1248],
	["Brain","-100k",19.4,1000]
]

var feb11Table3 = [
	["Model", "Parameters", "ms", "sec/ms", "#A100s","Param/ms","Param/ms/#A100s","words/sec","words/day","queries/day"],
	["3 billion", "3 billion", 6, 1000, 1],
	["ChatGPT 1GPU", "175 billion", 350, 1000, 1],
	["ChatGPT", "175 billion", 50, 1000, 8],
	["BLOOM 176B", "176 billion", 45, 1000, 8],
	["Human Brain", "1 quadrillion", 128, 1000,0.80]
]


function addBlogPost(parentElement,inputArray) {
	for (var i = 0; i < inputArray.length; i++) {
		addElement(parentElement,inputArray[i][0],"",inputArray[i][1],"","",inputArray[i][3],"","","","",inputArray[i][2]);
//addElement("elementParent","innerText","elementClass","elementType","elementStyle","href","onChange","onClick","contentEditable","attributeType","attributeAction","elementId")

//addElement("content","","","br")

	}
}
function runSynapses(synapseId){
	writeElement(synapseId+"synapseA",(readElement(synapseId+"synapseWeight")*1))
	writeElement(synapseId+"synapseB",(readElement(synapseId+"synapseWeight")*1))

	writeElement(synapseId+"outputA",readElement(synapseId+"inputA")*readElement(synapseId+"synapseA"))
	writeElement(synapseId+"outputB",readElement(synapseId+"inputB")*readElement(synapseId+"synapseB"))
	
	writeElement(synapseId+"activation",(readElement(synapseId+"outputA")*1)+(readElement(synapseId+"outputB")*1))
	if (readElement(synapseId+"activation") >= readElement(synapseId+"threshold")) {
		writeElement(synapseId+"output",1)
	} else {
		writeElement(synapseId+"output",0)
	}
	
}
function addNeuronRow(tableName,rowName,synapseId) {
	var tbody = returnTablePart(tableName,"TBODY").id
	var neuronRow = addElement(tbody,"","","tr")
	addElement(neuronRow,rowName,"","th")
	addElement(addElement(neuronRow,"","","td"),"[0,0]","","input","","","updateRow('"+rowName+"');propagateValues"+synapseId+"();","","","","",rowName+"inputs")
	addElement(addElement(neuronRow,"","","td"),"[0.6,0.6]","","input","","","updateRow('"+rowName+"');propagateValues"+synapseId+"();","","","","",rowName+"weights")
	addElement(addElement(neuronRow,"","","td"),"1","","input","","","updateRow('"+rowName+"');propagateValues"+synapseId+"();","","","","",rowName+"threshold")
	addElement(addElement(neuronRow,"","","td"),"","","","","","","","","","",rowName+"output")
	updateRow(rowName);
}
function updateRow(rowName){
	writeElement(rowName+"output",doNeuron(readElement(rowName+"inputs"),readElement(rowName+"weights"),readElement(rowName+"threshold")));
}
function propagateValues0206() {
	writeElement("Input-Ainputs","["+readElement("0206inputA")+","+readElement("0206inputB")+"]")
	updateRow("Input-A")
	writeElement("Input-Binputs","["+readElement("0206inputA")+","+readElement("0206inputB")+"]")
	updateRow("Input-B")

	writeElement("Mid-Ainputs","["+readElement('Input-Aoutput')+","+readElement('Input-Boutput')+"]")
	updateRow("Mid-A")
	writeElement("Mid-Binputs","["+readElement('Input-Aoutput')+","+readElement('Input-Boutput')+"]")
	updateRow("Mid-B")

	writeElement("Out-Ainputs","["+readElement('Mid-Aoutput')+","+readElement('Mid-Boutput')+"]")
	updateRow("Out-A")
	writeElement("Out-Binputs","["+readElement('Mid-Aoutput')+","+readElement('Mid-Boutput')+"]")
	updateRow("Out-B")
}
function propagateValues0211() {
	writeElement("Mid_Ainputs","["+readElement('0211input_A')+","+readElement('0211input_B')+"]")
	updateRow("Mid_A")
	writeElement("Mid_Binputs","["+readElement('0211input_A')+","+readElement('0211input_B')+"]")
	updateRow("Mid_B")
	writeElement("Mid_Cinputs","["+readElement('0211input_A')+","+readElement('0211input_B')+"]")
	updateRow("Mid_C")

	writeElement("Out_Ainputs","["+readElement('Mid_Aoutput')+","+readElement('Mid_Boutput')+","+readElement('Mid_Coutput')+"]")
	updateRow("Out_A")
}
function doNeuron(inputArray,weightArray,threshold){
	var accumulate = 0;
	inputArray = eval(inputArray)
	weightArray = eval(weightArray)
	threshold = eval(threshold)
	for (var i = 0;i<inputArray.length;i++) {
		accumulate += inputArray[i]*weightArray[i]
	}
	if (accumulate >= threshold) {
		return accumulate//1
	} else {
		return 0
	}
	
}

function build0204Table(parentElement){
	mdArrayToTable(parentElement,"0204Table",[["Title","A","B","Synapse Weight"]])
	var tbody = returnTablePart("0204Table","TBODY").id
	//addElement("elementParent","innerText","elementClass","elementType","elementStyle","href","onChange","onClick","contentEditable","attributeType","attributeAction","elementId")
	//addElement("elementParent","innerText","elementClass","elementType","","","","","","","","0204")

	var Inputsrow = addElement(tbody,"","","tr")
	addElement(Inputsrow,"Inputs","","th")
	addElement(addElement(Inputsrow,"","","td"),"1","","input","","","runSynapses('0204')","","","type","number","0204inputA")
	addElement(addElement(Inputsrow,"","","td"),"0","","input","","","runSynapses('0204')","","","type","number","0204inputB")

	var Synapsesrow = addElement(tbody,"","","tr")
	addElement(Synapsesrow,"Synapses","","th")
	addElement(Synapsesrow,"","","td","","","","","","","","0204synapseA")
	addElement(Synapsesrow,"","","td","","","","","","","","0204synapseB")
	addElement(addElement(Synapsesrow,"","","td"),"0.6","","input","","","runSynapses('0204')","","","type","number","0204synapseWeight")

	var Weightedrow = addElement(tbody,"","","tr")
	addElement(Weightedrow,"Weighted Output","","th")
	addElement(Weightedrow,"","","td","","","","","","","","0204outputA")
	addElement(Weightedrow,"","","td","","","","","","","","0204outputB")

	var Activationrow = addElement(tbody,"","","tr")
	addElement(Activationrow,"Activation","","th")
	addElement(Activationrow,"","","td","","","","","","","","0204activation")

	var Thresholdrow = addElement(tbody,"","","tr")
	addElement(Thresholdrow,"Threshold","","th")
	addElement(addElement(Thresholdrow,"","","td"),"1","","input","","","runSynapses('0204')","","","type","number","0204threshold")

	var Outputrow = addElement(tbody,"","","tr")
	addElement(Outputrow,"Output","","th")
	addElement(Outputrow,"","","td","","","","","","","","0204output")
}
</script>
<style type="text/css"> 
body {
}
.floatingBubble {
 display: inline-block;
 max-width: 98%;
}

.validInput {
	background-color:#d9ead3;
}

.saltine .house {
	text-align:center;
	vertical-align:center;
	padding:2px 3px 2px 3px;
}.saltine .house a {
	color: inherit;
} .s0{
	background-color:#ffd966;
}.s1{
	background-color:#ffe599;
} .s2{
	background-color:#fff2cc;
} .s3{
	background-color:#ffff00;
} .s4{
	background-color:#ff9900;
} .s5{
	background-color:#c9daf8;
} .s6{
	background-color:#f1c232;
} .s7{
} .tableYes{
	background-color:#D9EAD3;
} .tableNo{
	background-color:#F4CCCC;
} .tableMaybe{
	background-color:#FCE5CD;
}

.THeader {
	width:52px;
}
.TRow {
	height: 45px;
	line-height: 45px;
}

:root {
 --highlight-color: null;
 --foreground-color: null;
}

::selection {
 background: var(--highlight-color);
 color: var(--foreground-color);
}

</style>
		</div>
		<div id="navContainer">
			<nav>
                <ul>
                    <li><a>Blog ▼</a><ul>
                        <li><a href="/blog.html">Blog</a></li>
					</ul></li>
                    <li><a href="/history.html">World History</a></li>
                    <li><a>Stuff ▼</a><ul>
                        <li><a href="/Gillogisms.html">Gillogisms</a></li>
                    </ul></li>
                    <li><a href="/contact.html">Contact</a></li>
				</ul>
            </nav>
			</div><script>rebuildElement("navContainer");buildMenuPage("navContainer")</script>
		<div id="content">
			<div class="textBubbleBG"><h4>From the <a href="https://www.youtube.com/watch?v=CNUTlKqSO-I">sublime</a> to the <a href="https://www.youtube.com/watch?v=zy9FkAXMBfk">ridiculous</a>.</h4>
			</div><br /><br />
 			<div id="0211Bubble" class="textBubbleBG"><h1 id="0211Bubble"><a href="#02112023">02/11/2023</a> - Neural Networks - Part 5: You and me and the future makes three.</h1></div><br /><br />
			<div id="0209Bubble" class="textBubbleBG"><h1 id="0209Bubble"><a href="#02092023">02/09/2023</a> - Neural Networks - Part 4: Accumulated multiplication.</h1></div><br /><br />
			<div id="0206Bubble" class="textBubbleBG"><h1 id="0206Bubble"><a href="#02062023">02/06/2023</a> - Neural Networks - Part 3: Tying together a small net.</h1></div><br /><br />
			<div id="0205Bubble" class="textBubbleBG"><h1 id="0205Bubble"><a href="#02052023">02/05/2023</a> - Neural Networks - Part 2: Hardware is king</h1></div><br /><br />
			<div id="0204Bubble" class="textBubbleBG"><h1 id="0204Bubble"><a href="#02042023">02/04/2023</a> - Neural Networks - Part 1: Neuron.</h1></div>
<script>

addBlogPost("0211Bubble",feb11Blog);

mdArrayToTable("0211Table1Holder","0211Table1",feb11Table1)
columnMath("0211Table1",3,"0211Table1",2,0,"0211Table1",4,"divide",2,"true") //TOPS/W

mdArrayToTable("0211Table2Holder","0211Table2",[["Title","Synapses","Weights","Threshold","Output"]])
addNeuronRow("0211Table2","Mid_A","0211")
addNeuronRow("0211Table2","Mid_B","0211")
addNeuronRow("0211Table2","Mid_C","0211")
addNeuronRow("0211Table2","Out_A","0211")
writeElement("Out_Ainputs","["+readElement('Mid_Aoutput')+","+readElement('Mid_Boutput')+","+readElement('Mid_Coutput')+"]")
writeElement("Out_Aweights","[0.6,0.6,0.6]")

mdArrayToTable("0211Table3Holder","0211Table3",feb11Table3)
columnMath("0211Table3",1,"0211Table3",2,0,"0211Table3",5,"divide",2,"true") //Param/ms
columnMath("0211Table3",5,"0211Table3",4,0,"0211Table3",6,"divide",2,"true") //Param/ms/#A110s
columnMath("0211Table3",3,"0211Table3",2,0,"0211Table3",7,"divide",2,"true") //words/sec
columnMath("0211Table3",7,"",86400,0,"0211Table3",8,"multiply",2,"true") //words/day
columnMath("0211Table3",8,"",30,0,"0211Table3",9,"divide",2,"true") //queries/day

//addLinkToWord("0211Bubble","Drexler 2018","https://aiimpacts.org/brain-performance-in-flops/#Drexler_2018")
//addLinkToWord("0211Bubble","David Ireland on Stack Exchange","https://ai.stackexchange.com/questions/22673/what-exactly-are-the-parameters-in-gpt-3s-175-billion-parameters-and-how-are#comment34649_22673")



addBlogPost("0209Bubble",feb9Blog);

mdArrayToTable("0209Table2Holder","0209Table2",feb9Table)
columnMath("0209Table2",8,"0209Table2",7,0,"0209Table2",9,"divide",2,"") //TOPS/W

addLinkToWord("0209Bubble","AIPU was already taken","https://ubhc.rutgers.edu/clinical/inpatient/adult-inpatient-services.xml")
addLinkToWord("0209Bubble","Ergo's tremendous","https://www.embedded.com/edge-ai-chip-forgoes-multiply-accumulate-array-to-reach-55-tops-w/")
addLinkToWord("0209Bubble","TOPS/Watts","http://topsperwatt.com/")
addLinkToWord("0209Bubble","2 kW just for A100s","https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/")
addLinkToWord("0209Bubble","need TPUs","https://www.makeuseof.com/what-is-tpu-how-is-it-used/")
addLinkToWord("0209Bubble","more efficient than the A100","https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf")




addBlogPost("0206Bubble",feb6Blog);
addBlogPost("list0206",feb6List);

mdArrayToTable("0206TableHolder","0206Table",[["Title","Synapses","Weights","Threshold","Output"]])
addNeuronRow("0206Table","Input-A","0206")
addNeuronRow("0206Table","Input-B","0206")
addNeuronRow("0206Table","Mid-A","0206")
addNeuronRow("0206Table","Mid-B","0206")
addNeuronRow("0206Table","Out-A","0206")
addNeuronRow("0206Table","Out-B","0206")
propagateValues0206();


addBlogPost("0205Bubble",feb5Blog);

mdArrayToTable("0205Table1Holder","0205Table1",feb5Table1)
mdArrayToTable("0205Table2Holder","0205Table2",feb5Table2)
mdArrayToTable("0205Table3Holder","0205Table3",feb5Table3)

columnMath("0205Table1",2,"0205Table1",3,0,"0205Table1",4,"add",2,"") //Total/mo
columnMath("0205Table1",4,"",30,0,"0205Table1",5,"divide",2,"") //Total/day
columnMath("0205Table1",5,"",24,0,"0205Table1",6,"divide",2,"") //Total/hour
columnMath("0205Table1",6,"0205Table1",1,0,"0205Table1",7,"divide",2,"") //Total/hour/A100

columnMath("0205Table2",1,"0205Table2",2,0,"0205Table2",5,"divide",2,"true") //Param/ms
columnMath("0205Table2",5,"0205Table2",4,0,"0205Table2",6,"divide",2,"true") //Param/ms/#A100s
columnMath("0205Table2",3,"0205Table2",2,0,"0205Table2",7,"divide",2,"true") //words/sec
columnMath("0205Table2",7,"",86400,0,"0205Table2",8,"multiply",2,"true") //words/day
columnMath("0205Table2",8,"",30,0,"0205Table2",9,"divide",2,"true") //queries/day

columnMath("0205Table3",1,"",174,0,"0205Table3",2,"multiply",2,"") //174 servers

addLinkToWord("0205Bubble","02/05/2023","#02052023")
addLinkToWord("0205Bubble","Tom Goldstein","https://twitter.com/tomgoldsteincs/status/1600296981955050694")
addLinkToWord("0205Bubble","Azure pricing calculator","https://azure.microsoft.com/en-us/pricing/calculator/")
addLinkToWord("0205Bubble","Mayank Mishra","https://huggingface.co/blog/bloom-inference-pytorch-scripts")
addLinkToWord("0205Bubble","specific model of server","https://azureprice.net/vm/Standard_ND96amsr_A100_v4")




addBlogPost("0204Bubble",feb4Blog);
build0204Table("0204TableHolder");
addBlogPost("list0204",feb4List);
runSynapses('0204');
</script>
		   
		</div><!-- End Content-->
		<div id="footWrapper">
			<div class="container-fluid">
			</div>
			<div id="spacerName">
				<br>
				<br>
			</div>
			<div id="errDiv" class="row img-rounded">
			</div>
			<div id="footerStatic" class="navbar-static-bottom" style="text-align: center;">
				<p class="copyright">© 2013-2023 Gilgamech Technologies - Powered by <a href="https://www.Sparational.com/">Sparational.js</a>.</p>
			</div>
		</div>
	</body>
</html>